{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets trl peft bitsandbytes==0.45.0 \n",
    "!pip install --upgrade pip\n",
    "!pip install unsloth unsloth_zoo --no-cache-dir --upgrade\n",
    "!pip install vllm\n",
    "!pip install --upgrade pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 04-07 08:37:31 __init__.py:207] Automatically detected platform cuda.\n",
      "==((====))==  Unsloth 2025.3.19: Fast Qwen2 patching. Transformers: 4.49.0. vLLM: 0.7.3.\n",
      "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.168 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit with actual GPU utilization = 49.49%\n",
      "Unsloth: Your GPU has CUDA compute capability 8.9 with VRAM = 22.17 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 1024. Num Sequences = 224.\n",
      "Unsloth: vLLM's KV Cache can use up to 8.55 GB. Also swap space = 6 GB.\n",
      "INFO 04-07 08:37:43 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'embed', 'classify', 'score'}. Defaulting to 'generate'.\n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.30.mlp'], 'llm_int8_threshold': 6.0}\n",
      "INFO 04-07 08:37:43 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":224}, use_cached_outputs=False, \n",
      "INFO 04-07 08:37:44 cuda.py:229] Using Flash Attention backend.\n",
      "INFO 04-07 08:37:44 model_runner.py:1110] Starting to load model unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit...\n",
      "INFO 04-07 08:37:44 loader.py:1089] Loading weights with BitsAndBytes quantization.  May take a while ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W407 08:37:44.819087033 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 08:37:45 weight_utils.py:254] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9722792042f493fb96cab1c208bce6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125d59d4fa234a41b3e120be320b6221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 08:37:46 model_runner.py:1115] Loading model weights took 2.2160 GB\n",
      "INFO 04-07 08:37:46 punica_selector.py:18] Using PunicaWrapperGPU.\n",
      "INFO 04-07 08:37:49 worker.py:267] Memory profiling takes 2.26 seconds\n",
      "INFO 04-07 08:37:49 worker.py:267] the current vLLM instance can use total_gpu_memory (22.17GiB) x gpu_memory_utilization (0.49) = 10.97GiB\n",
      "INFO 04-07 08:37:49 worker.py:267] model weights take 2.22GiB; non_torch_memory takes 0.04GiB; PyTorch activation peak memory takes 1.23GiB; the rest of the memory reserved for KV Cache is 7.48GiB.\n",
      "INFO 04-07 08:37:49 executor_base.py:111] # cuda blocks: 13623, # CPU blocks: 10922\n",
      "INFO 04-07 08:37:49 executor_base.py:116] Maximum concurrency for 1024 tokens per request: 212.86x\n",
      "INFO 04-07 08:37:55 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:26<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 08:38:21 model_runner.py:1562] Graph capturing finished in 26 secs, took 4.41 GiB\n",
      "INFO 04-07 08:38:21 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 34.42 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Unsloth 2025.3.19 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "import unsloth, torch\n",
    "from transformers import AutoTokenizer, TextStreamer\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "def load_model_tokenizer_ft(base_model_id=\"Qwen/Qwen2.5-3B-Instruct\", adapter_path=\"grpo_lora\"):\n",
    "    # Load the base model\n",
    "    base_model, _ = FastLanguageModel.from_pretrained(\n",
    "        model_name=base_model_id,\n",
    "        max_seq_length=1024,         # Same as during training\n",
    "        load_in_4bit=True,           # Load in 4-bit for memory efficiency\n",
    "        fast_inference=True,         # Enable fast inference\n",
    ")\n",
    "\n",
    "    # Apply LoRA weights (need to be the same as before)\n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "        base_model,\n",
    "        r=16,  # Same rank as during training\n",
    "        target_modules=[\n",
    "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "            \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "        ],\n",
    "        lora_alpha=32,  # Same alpha as during training\n",
    "        use_gradient_checkpointing=\"unsloth\",  # Enable gradient checkpointing if needed\n",
    "        random_state=3407,  # Same random state as during training\n",
    "    )\n",
    "    # Load the saved LoRA weights\n",
    "    model.load_adapter(adapter_path,adapter_name=\"default\")\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Load the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "    return base_model, model, tokenizer\n",
    "\n",
    "model_base, model_ft, tokenizer =  load_model_tokenizer_ft()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "\n",
    "\n",
    "# extract tool call from the response\n",
    "def extract_tool_call(text):\n",
    "  import io\n",
    "  from contextlib import redirect_stdout\n",
    "  # pattern: tool_code + white spaces + character + white spaces\n",
    "  pattern=r\"```tool_code\\s*(.*?)\\s*```\"\n",
    "  matches=re.search(pattern, text, re.DOTALL)\n",
    "  if matches:\n",
    "      tool_code=matches.group(1).strip()\n",
    "      # capture stdout in a string buffer: to capture the output generated by the function eval(tool_code), e.g. function contains print statement\n",
    "      f=io.StringIO()\n",
    "      # eval executes the extracted code as if it were a Python expression\n",
    "      with redirect_stdout(f):\n",
    "          result=eval(tool_code)\n",
    "      output=f.getvalue()\n",
    "      r=result if output== '' else output\n",
    "      return f'```tool_output\\n{str(r).strip()}\\n```'\n",
    "  return None\n",
    "\n",
    "\n",
    "def convert(amount: float, currency: str, new_currency: str) -> float:\n",
    "  return amount * 0.9\n",
    "\n",
    "\n",
    "def get_exchange_rate(currency: str, new_currency: str) -> float:\n",
    "    return 1.2\n",
    "\n",
    "\n",
    "def bezout(a,b):\n",
    "    # swap a and b if necessary\n",
    "    swap=False # indicate if we need to swap and b\n",
    "    if a<b:\n",
    "        swap=True\n",
    "        a,b=b,a\n",
    "\n",
    "    # keep track the list of remainders, coefficients a[i] and b[i], quotients q[i]\n",
    "    remainders=[a,b]   # store remainders r[0], r[1], r[2], ...\n",
    "    coeff_a=[1,0]      # store coefficients a[0], a[1], a[2], ...\n",
    "    coeff_b=[0,1]      # store coefficients b[0], b[1], b[2], ...\n",
    "    quotients=list()   # store quotients q[0], q[1], q[2], ...\n",
    "\n",
    "    while b>0:\n",
    "        # continously divide a by b and update them\n",
    "        q=a//b\n",
    "        a,b=b,a-b*q\n",
    "\n",
    "        # update the lists\n",
    "        remainders.append(b)\n",
    "        quotients.append(q)\n",
    "        coeff_a.append(coeff_a[-2]-q*coeff_a[-1])\n",
    "        coeff_b.append(coeff_b[-2]-q*coeff_b[-1])\n",
    "\n",
    "    if swap:\n",
    "        return coeff_b[-2], coeff_a[-2]\n",
    "    else:\n",
    "        return coeff_a[-2], coeff_b[-2]\n",
    "\n",
    "def solve(a,b,m):\n",
    "    d=math.gcd(a,m)\n",
    "\n",
    "    # no solution if b is not divisible by d\n",
    "    if b%d!=0:\n",
    "        print(\"No solution!\")\n",
    "\n",
    "    # divide a,b,m by d and solve the resulting equation\n",
    "    else:\n",
    "        a,b,m=a//d, b//d, m//d\n",
    "        a_inverse=bezout(a,m)[0]\n",
    "        x=a_inverse*b % m\n",
    "        print(f\"Solution : x = {x} (mod {m})\")\n",
    "\n",
    "instruction_prompt_with_function_calling = '''\n",
    "At each turn, if you decide to invoke any of the functions, you must wrap the function call with triple backticks and the label \"tool_code\". You are given several Python functions that you can use, and you are only allowed to call these functions. The generated code should be readable, efficient, and match exactly the provided function signature.\n",
    "\n",
    "When a function call is made, its output will be wrapped in triple backticks with the label \"tool_output\". Use that output to guide any further tool calls or to generate a friendly response.\n",
    "\n",
    "Your task is to determine which of the following functions to call based solely on the user's request. If the request refers to computing the Bezout coefficients, then your answer must be exactly a function call to `bezout` with the appropriate parameters, wrapped as shown below.\n",
    "\n",
    "For example, if the user asks: \"What are bezout coefficients of 12 and 21?\" then you must respond with:\n",
    "```tool_code\n",
    "bezout(a=12, b=21)\n",
    "```\n",
    "\n",
    "The available Python methods are:\n",
    "\n",
    "```python\n",
    "def convert(amount: float, currency: str, new_currency: str) -> float:\n",
    "    \"\"\"Convert the currency with the latest exchange rate\n",
    "\n",
    "    Args:\n",
    "      amount: The amount of currency to convert\n",
    "      currency: The currency to convert from\n",
    "      new_currency: The currency to convert to\n",
    "    \"\"\"\n",
    "\n",
    "def get_exchange_rate(currency: str, new_currency: str) -> float:\n",
    "    \"\"\"Get the latest exchange rate for the currency pair\n",
    "\n",
    "    Args:\n",
    "      currency: The currency to convert from\n",
    "      new_currency: The currency to convert to\n",
    "    \"\"\"\n",
    "\n",
    "def bezout(a:int , b: int) -> List[int]:\n",
    "    \"\"\"Compute the Bezout coefficients of a and b\n",
    "\n",
    "    Args:\n",
    "      a: The first number\n",
    "      b: The second number\n",
    "    \"\"\"\n",
    "\n",
    "def solve(a,b,m):\n",
    "    \"\"\"Solve the linear congruence equation ax=b (mod m)\n",
    "\n",
    "    Args:\n",
    "      a: The coefficient of x in the equation\n",
    "      b: The right-hand side of the equation\n",
    "      m: The modulus of the equation\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "User: {user_message}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent_Base:\n",
    "    def __init__(self, system_message=\"\", stream_output=True):\n",
    "        self.messages = []\n",
    "        self.stream_output = stream_output\n",
    "        if system_message:\n",
    "            self.messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "    def __call__(self, message, stream=None):\n",
    "        # Use parameter stream if provided, otherwise use instance default\n",
    "        should_stream = self.stream_output if stream is None else stream\n",
    "        \n",
    "        # user message\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        response = self.execute(stream=should_stream)\n",
    "\n",
    "        # Add the assistant's response to the message history\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response\n",
    "\n",
    "    def execute(self, stream=True):\n",
    "        # apply chat template \n",
    "        text = tokenizer.apply_chat_template(\n",
    "            self.messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        # Only use TextStreamer if streaming is enabled\n",
    "        streamer = TextStreamer(tokenizer, skip_special_tokens=True) if stream else None\n",
    "        \n",
    "        generated_ids = model_base.generate(\n",
    "            **model_inputs,\n",
    "            # temperature=0.1,  # Control randomness (lower = more deterministic)\n",
    "            # top_p=0.9,   \n",
    "            streamer=streamer\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return response\n",
    "\n",
    "def query(question):\n",
    "    # initialize agent\n",
    "    bot = Agent_Base()\n",
    "    # get instruction prompt\n",
    "    prompt = instruction_prompt_with_function_calling.format(user_message=question)\n",
    "    # get tool call - stream this first interaction\n",
    "    response = bot(prompt, stream=True)         \n",
    "    # get output of tool function\n",
    "    call_response = extract_tool_call(response)\n",
    "    if call_response is None:\n",
    "        return None\n",
    "    print(\"Tool call:\\n\", call_response)\n",
    "\n",
    "    # don't stream the second interaction\n",
    "    answer = bot(call_response, stream=False)\n",
    "    return answer\n",
    "\n",
    "\n",
    "# question = \"What are bezout coefficients of 12 and 21?\"\n",
    "# answer = query(question)\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "user\n",
      "\n",
      "At each turn, if you decide to invoke any of the functions, you must wrap the function call with triple backticks and the label \"tool_code\". You are given several Python functions that you can use, and you are only allowed to call these functions. The generated code should be readable, efficient, and match exactly the provided function signature.\n",
      "\n",
      "When a function call is made, its output will be wrapped in triple backticks with the label \"tool_output\". Use that output to guide any further tool calls or to generate a friendly response.\n",
      "\n",
      "Your task is to determine which of the following functions to call based solely on the user's request. If the request refers to computing the Bezout coefficients, then your answer must be exactly a function call to `bezout` with the appropriate parameters, wrapped as shown below.\n",
      "\n",
      "For example, if the user asks: \"What are bezout coefficients of 12 and 21?\" then you must respond with:\n",
      "```tool_code\n",
      "bezout(a=12, b=21)\n",
      "```\n",
      "\n",
      "The available Python methods are:\n",
      "\n",
      "```python\n",
      "def convert(amount: float, currency: str, new_currency: str) -> float:\n",
      "    \"\"\"Convert the currency with the latest exchange rate\n",
      "\n",
      "    Args:\n",
      "      amount: The amount of currency to convert\n",
      "      currency: The currency to convert from\n",
      "      new_currency: The currency to convert to\n",
      "    \"\"\"\n",
      "\n",
      "def get_exchange_rate(currency: str, new_currency: str) -> float:\n",
      "    \"\"\"Get the latest exchange rate for the currency pair\n",
      "\n",
      "    Args:\n",
      "      currency: The currency to convert from\n",
      "      new_currency: The currency to convert to\n",
      "    \"\"\"\n",
      "\n",
      "def bezout(a:int , b: int) -> List[int]:\n",
      "    \"\"\"Compute the Bezout coefficients of a and b\n",
      "\n",
      "    Args:\n",
      "      a: The first number\n",
      "      b: The second number\n",
      "    \"\"\"\n",
      "\n",
      "def solve(a,b,m):\n",
      "    \"\"\"Solve the linear congruence equation ax=b (mod m)\n",
      "\n",
      "    Args:\n",
      "      a: The coefficient of x in the equation\n",
      "      b: The right-hand side of the equation\n",
      "      m: The modulus of the equation\n",
      "    \"\"\"\n",
      "```\n",
      "\n",
      "User: Solve the linear congruence equation 12x=1 (mod 27)\n",
      "\n",
      "assistant\n",
      "```tool_code\n",
      "solve(a=12, b=1, m=27)\n",
      "```\n",
      "Tool call:\n",
      " ```tool_output\n",
      "No solution!\n",
      "```\n",
      "The given linear congruence equation \\(12x \\equiv 1 \\pmod{27}\\) has no solution because 12 and 27 are not coprime (they share a common divisor other than 1), and the greatest common divisor (gcd) of 12 and 27 is 3, which does not divide 1. Therefore, there is no integer \\(x\\) that satisfies the equation.\n"
     ]
    }
   ],
   "source": [
    "question = \"Solve the linear congruence equation 12x=1 (mod 27)\"\n",
    "answer = query(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "user\n",
      "\n",
      "At each turn, if you decide to invoke any of the functions, you must wrap the function call with triple backticks and the label \"tool_code\". You are given several Python functions that you can use, and you are only allowed to call these functions. The generated code should be readable, efficient, and match exactly the provided function signature.\n",
      "\n",
      "When a function call is made, its output will be wrapped in triple backticks with the label \"tool_output\". Use that output to guide any further tool calls or to generate a friendly response.\n",
      "\n",
      "Your task is to determine which of the following functions to call based solely on the user's request. If the request refers to computing the Bezout coefficients, then your answer must be exactly a function call to `bezout` with the appropriate parameters, wrapped as shown below.\n",
      "\n",
      "For example, if the user asks: \"What are bezout coefficients of 12 and 21?\" then you must respond with:\n",
      "```tool_code\n",
      "bezout(a=12, b=21)\n",
      "```\n",
      "\n",
      "The available Python methods are:\n",
      "\n",
      "```python\n",
      "def convert(amount: float, currency: str, new_currency: str) -> float:\n",
      "    \"\"\"Convert the currency with the latest exchange rate\n",
      "\n",
      "    Args:\n",
      "      amount: The amount of currency to convert\n",
      "      currency: The currency to convert from\n",
      "      new_currency: The currency to convert to\n",
      "    \"\"\"\n",
      "\n",
      "def get_exchange_rate(currency: str, new_currency: str) -> float:\n",
      "    \"\"\"Get the latest exchange rate for the currency pair\n",
      "\n",
      "    Args:\n",
      "      currency: The currency to convert from\n",
      "      new_currency: The currency to convert to\n",
      "    \"\"\"\n",
      "\n",
      "def bezout(a:int , b: int) -> List[int]:\n",
      "    \"\"\"Compute the Bezout coefficients of a and b\n",
      "\n",
      "    Args:\n",
      "      a: The first number\n",
      "      b: The second number\n",
      "    \"\"\"\n",
      "\n",
      "def solve(a,b,m):\n",
      "    \"\"\"Solve the linear congruence equation ax=b (mod m)\n",
      "\n",
      "    Args:\n",
      "      a: The coefficient of x in the equation\n",
      "      b: The right-hand side of the equation\n",
      "      m: The modulus of the equation\n",
      "    \"\"\"\n",
      "```\n",
      "\n",
      "User: What are bezout coefficients of 12 and 21?\n",
      "\n",
      "assistant\n",
      "```tool_code\n",
      "bezout(a=12, b=21)\n",
      "```\n",
      "Tool call:\n",
      " ```tool_output\n",
      "(2, -1)\n",
      "```\n",
      "The Bezout coefficients for 12 and 21 are 2 and -1, respectively. This means that 12*2 + 21*(-1) â‰¡ 0 (mod 21).\n"
     ]
    }
   ],
   "source": [
    "class Agent_ft:\n",
    "    def __init__(self, system_message=\"\", stream_output=True):\n",
    "        self.messages = []\n",
    "        self.stream_output = stream_output\n",
    "        if system_message:\n",
    "            self.messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "    def __call__(self, message, stream=None):\n",
    "        # Use parameter stream if provided, otherwise use instance default\n",
    "        should_stream = self.stream_output if stream is None else stream\n",
    "        \n",
    "        # user message\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        response = self.execute(stream=should_stream)\n",
    "\n",
    "        # Add the assistant's response to the message history\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response\n",
    "\n",
    "    def execute(self, stream=True):\n",
    "        # apply chat template \n",
    "        text = tokenizer.apply_chat_template(\n",
    "            self.messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        # Only use TextStreamer if streaming is enabled\n",
    "        streamer = TextStreamer(tokenizer, skip_special_tokens=True) if stream else None\n",
    "        \n",
    "        generated_ids = model_ft.generate(\n",
    "            **model_inputs,\n",
    "            # temperature=0.1,  # Control randomness (lower = more deterministic)\n",
    "            # top_p=0.9,   \n",
    "            streamer=streamer\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return response\n",
    "\n",
    "def query_ft(question):\n",
    "    # initialize agent\n",
    "    bot = Agent_ft()\n",
    "    # get instruction prompt\n",
    "    prompt = instruction_prompt_with_function_calling.format(user_message=question)\n",
    "    # get tool call - stream this first interaction\n",
    "    response = bot(prompt, stream=True)         \n",
    "    # get output of tool function\n",
    "    call_response = extract_tool_call(response)\n",
    "    if call_response is None:\n",
    "        return None\n",
    "    print(\"Tool call:\\n\", call_response)\n",
    "\n",
    "    # don't stream the second interaction\n",
    "    answer = bot(call_response, stream=False)\n",
    "    return answer\n",
    "\n",
    "\n",
    "question = \"What are bezout coefficients of 12 and 21?\"\n",
    "answer = query_ft(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "user\n",
      "\n",
      "At each turn, if you decide to invoke any of the functions, you must wrap the function call with triple backticks and the label \"tool_code\". You are given several Python functions that you can use, and you are only allowed to call these functions. The generated code should be readable, efficient, and match exactly the provided function signature.\n",
      "\n",
      "When a function call is made, its output will be wrapped in triple backticks with the label \"tool_output\". Use that output to guide any further tool calls or to generate a friendly response.\n",
      "\n",
      "Your task is to determine which of the following functions to call based solely on the user's request. If the request refers to computing the Bezout coefficients, then your answer must be exactly a function call to `bezout` with the appropriate parameters, wrapped as shown below.\n",
      "\n",
      "For example, if the user asks: \"What are bezout coefficients of 12 and 21?\" then you must respond with:\n",
      "```tool_code\n",
      "bezout(a=12, b=21)\n",
      "```\n",
      "\n",
      "The available Python methods are:\n",
      "\n",
      "```python\n",
      "def convert(amount: float, currency: str, new_currency: str) -> float:\n",
      "    \"\"\"Convert the currency with the latest exchange rate\n",
      "\n",
      "    Args:\n",
      "      amount: The amount of currency to convert\n",
      "      currency: The currency to convert from\n",
      "      new_currency: The currency to convert to\n",
      "    \"\"\"\n",
      "\n",
      "def get_exchange_rate(currency: str, new_currency: str) -> float:\n",
      "    \"\"\"Get the latest exchange rate for the currency pair\n",
      "\n",
      "    Args:\n",
      "      currency: The currency to convert from\n",
      "      new_currency: The currency to convert to\n",
      "    \"\"\"\n",
      "\n",
      "def bezout(a:int , b: int) -> List[int]:\n",
      "    \"\"\"Compute the Bezout coefficients of a and b\n",
      "\n",
      "    Args:\n",
      "      a: The first number\n",
      "      b: The second number\n",
      "    \"\"\"\n",
      "\n",
      "def solve(a,b,m):\n",
      "    \"\"\"Solve the linear congruence equation ax=b (mod m)\n",
      "\n",
      "    Args:\n",
      "      a: The coefficient of x in the equation\n",
      "      b: The right-hand side of the equation\n",
      "      m: The modulus of the equation\n",
      "    \"\"\"\n",
      "```\n",
      "\n",
      "User: Solve the linear congruence equation 36x=3 (mod 27)\n",
      "\n",
      "assistant\n",
      "```tool_code\n",
      "solve(a=36, b=3, m=27)\n",
      "```\n",
      "Tool call:\n",
      " ```tool_output\n",
      "No solution!\n",
      "```\n",
      "The provided input to the `solve` function resulted in \"No solution!\", which typically means that the linear congruence equation \\(36x \\equiv 3 \\pmod{27}\\) has no solution because the greatest common divisor (gcd) of 36 and 27 is 9, and 3 is not divisible by 9. Therefore, there is no integer \\(x\\) that satisfies the equation.\n"
     ]
    }
   ],
   "source": [
    "question = \"Solve the linear congruence equation 36x=3 (mod 27)\"\n",
    "answer = query_ft(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finetuned model with chain of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_prompt = '''\n",
    "At each turn, if you decide to invoke any of the functions, you must wrap the function call with triple backticks and the label \"tool_code\". You are given several Python functions that you can use, and you are only allowed to call these functions. \n",
    "\n",
    "When a function call is made, its output will be wrapped in triple backticks with the label \"tool_output\". Use that output to guide any further tool calls or to generate a friendly response.\n",
    "\n",
    "Your task is to determine which of the following functions to call based solely on the user's request. If the request is not relevant to any function, simply answer it without invoking any function call. \n",
    "\n",
    "For example, if the user asks: \"What are bezout coefficients of 12 and 21?\" then you must respond with:\n",
    "```tool_code\n",
    "bezout(a=12, b=21)\n",
    "```\n",
    "\n",
    "The available Python methods are:\n",
    "\n",
    "```python\n",
    "def convert(amount: float, currency: str, new_currency: str) -> float:\n",
    "    \"\"\"Convert the currency with the latest exchange rate\n",
    "\n",
    "    Args:\n",
    "      amount: The amount of currency to convert\n",
    "      currency: The currency to convert from\n",
    "      new_currency: The currency to convert to\n",
    "    \"\"\"\n",
    "\n",
    "def get_exchange_rate(currency: str, new_currency: str) -> float:\n",
    "    \"\"\"Get the latest exchange rate for the currency pair\n",
    "\n",
    "    Args:\n",
    "      currency: The currency to convert from\n",
    "      new_currency: The currency to convert to\n",
    "    \"\"\"\n",
    "\n",
    "def bezout(a:int , b: int) -> List[int]:\n",
    "    \"\"\"Compute the Bezout coefficients of a and b\n",
    "\n",
    "    Args:\n",
    "      a: The first number\n",
    "      b: The second number\n",
    "    \"\"\"\n",
    "\n",
    "def solve(a,b,m):\n",
    "    \"\"\"Solve the linear congruence equation ax=b (mod m)\n",
    "\n",
    "    Args:\n",
    "      a: The coefficient of x in the equation\n",
    "      b: The right-hand side of the equation\n",
    "      m: The modulus of the equation\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "User: {user_message}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "user\n",
      "\n",
      "You are a specialized assistant provided with a set of Python functions to perform specific computational tasks. Your task is to decide whether to answer the user's request with a plain text response or to call one of the provided functions.\n",
      "\n",
      "When a function call is made, its output will be wrapped in triple backticks with the label \"tool_output\". Use that output to guide any further tool calls or to generate a friendly response.\n",
      "\n",
      "Guidelines:\n",
      "1. Only call a function if and only if the user's request clearly maps to one of the functions below.\n",
      "2. In cases of ambiguity, always choose to answer in plain text rather than risk an unnecessary function call.\n",
      "3. When you decide to call a function, format your call with triple backticks labeled \"tool_code\" (see example below).\n",
      "\n",
      "Example: If the user asks: \"What are bezout coefficients of 12 and 21?\" then you must respond with:\n",
      "```tool_code\n",
      "bezout(a=12, b=21)\n",
      "```\n",
      "\n",
      "The available Python methods are:\n",
      "\n",
      "```python\n",
      "def convert(amount: float, currency: str, new_currency: str) -> float:\n",
      "    \"\"\"Convert the currency with the latest exchange rate\n",
      "\n",
      "    Args:\n",
      "      amount: The amount of currency to convert\n",
      "      currency: The currency to convert from\n",
      "      new_currency: The currency to convert to\n",
      "    \"\"\"\n",
      "\n",
      "def get_exchange_rate(currency: str, new_currency: str) -> float:\n",
      "    \"\"\"Get the latest exchange rate for the currency pair\n",
      "\n",
      "    Args:\n",
      "      currency: The currency to convert from\n",
      "      new_currency: The currency to convert to\n",
      "    \"\"\"\n",
      "\n",
      "def bezout(a:int , b: int) -> List[int]:\n",
      "    \"\"\"Compute the Bezout coefficients of a and b\n",
      "\n",
      "    Args:\n",
      "      a: The first number\n",
      "      b: The second number\n",
      "    \"\"\"\n",
      "\n",
      "def solve(a,b,m):\n",
      "    \"\"\"Solve the linear congruence equation ax=b (mod m)\n",
      "\n",
      "    Args:\n",
      "      a: The coefficient of x in the equation\n",
      "      b: The right-hand side of the equation\n",
      "      m: The modulus of the equation\n",
      "    \"\"\"\n",
      "```\n",
      "\n",
      "User: Solve the linear congruence equation 12x=10 (mod 34)\n",
      "\n",
      "assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```tool_code\n",
      "solve(a=12, b=10, m=34)\n",
      "```\n",
      "```tool_output\n",
      "Solution : x = 15 (mod 17)\n",
      "```\n",
      "The solution to the linear congruence equation \\(12x \\equiv 10 \\pmod{34}\\) is \\(x \\equiv 15 \\pmod{17}\\).\n"
     ]
    }
   ],
   "source": [
    "instruction_prompt = '''\n",
    "You are a specialized assistant provided with a set of Python functions to perform specific computational tasks. Your task is to decide whether to answer the user's request with a plain text response or to call one of the provided functions.\n",
    "\n",
    "When a function call is made, its output will be wrapped in triple backticks with the label \"tool_output\". Use that output to guide any further tool calls or to generate a friendly response.\n",
    "\n",
    "Guidelines:\n",
    "1. Only call a function if and only if the user's request clearly maps to one of the functions below.\n",
    "2. In cases of ambiguity, always choose to answer in plain text rather than risk an unnecessary function call.\n",
    "3. When you decide to call a function, format your call with triple backticks labeled \"tool_code\" (see example below).\n",
    "\n",
    "Example: If the user asks: \"What are bezout coefficients of 12 and 21?\" then you must respond with:\n",
    "```tool_code\n",
    "bezout(a=12, b=21)\n",
    "```\n",
    "\n",
    "The available Python methods are:\n",
    "\n",
    "```python\n",
    "def convert(amount: float, currency: str, new_currency: str) -> float:\n",
    "    \"\"\"Convert the currency with the latest exchange rate\n",
    "\n",
    "    Args:\n",
    "      amount: The amount of currency to convert\n",
    "      currency: The currency to convert from\n",
    "      new_currency: The currency to convert to\n",
    "    \"\"\"\n",
    "\n",
    "def get_exchange_rate(currency: str, new_currency: str) -> float:\n",
    "    \"\"\"Get the latest exchange rate for the currency pair\n",
    "\n",
    "    Args:\n",
    "      currency: The currency to convert from\n",
    "      new_currency: The currency to convert to\n",
    "    \"\"\"\n",
    "\n",
    "def bezout(a:int , b: int) -> List[int]:\n",
    "    \"\"\"Compute the Bezout coefficients of a and b\n",
    "\n",
    "    Args:\n",
    "      a: The first number\n",
    "      b: The second number\n",
    "    \"\"\"\n",
    "\n",
    "def solve(a,b,m):\n",
    "    \"\"\"Solve the linear congruence equation ax=b (mod m)\n",
    "\n",
    "    Args:\n",
    "      a: The coefficient of x in the equation\n",
    "      b: The right-hand side of the equation\n",
    "      m: The modulus of the equation\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "User: {user_message}\n",
    "'''\n",
    "class Agent_ft2:\n",
    "    def __init__(self, system_message=\"\", stream_output=True):\n",
    "        self.messages = []\n",
    "        self.stream_output = stream_output\n",
    "        if system_message:\n",
    "            self.messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "    def __call__(self, message, stream=None):\n",
    "        # Use parameter stream if provided, otherwise use instance default\n",
    "        should_stream = self.stream_output if stream is None else stream\n",
    "        \n",
    "        # user message\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        response = self.execute(stream=should_stream)\n",
    "\n",
    "        # Add the assistant's response to the message history\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response\n",
    "\n",
    "    def execute(self, stream=True):\n",
    "        # apply chat template \n",
    "        text = tokenizer.apply_chat_template(\n",
    "            self.messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        # Only use TextStreamer if streaming is enabled\n",
    "        streamer = TextStreamer(tokenizer, skip_special_tokens=True) if stream else None\n",
    "        \n",
    "        generated_ids = model_ft.generate(\n",
    "            **model_inputs,\n",
    "            # temperature=0.1,  # Control randomness (lower = more deterministic)\n",
    "            # top_p=0.9,   \n",
    "            streamer=streamer\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return response\n",
    "\n",
    "def query_ft2(question):\n",
    "    # initialize agent\n",
    "    bot = Agent_ft()\n",
    "    # get instruction prompt\n",
    "    prompt = instruction_prompt.format(user_message=question)\n",
    "    # get tool call - stream this first interaction\n",
    "    response = bot(prompt, stream=True)         \n",
    "    \n",
    "    # get output of tool function\n",
    "    call_response = extract_tool_call(response)\n",
    "\n",
    "    if call_response is None:\n",
    "        return \n",
    "    print(call_response)\n",
    "\n",
    "    # don't stream the second interaction\n",
    "    # call_response is added to messages with \"user\" role\n",
    "    answer = bot(call_response, stream=False)\n",
    "    return answer\n",
    "\n",
    "\n",
    "question = \"Solve the linear congruence equation 12x=10 (mod 34)\"\n",
    "answer = query_ft2(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
